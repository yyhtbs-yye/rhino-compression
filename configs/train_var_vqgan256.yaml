_import: configs/train_base_data.yaml

boat:
  path: 'rhcompression.boats.var_vqgan_boat'                # <- update to your actual module path
  name: 'VARVQGANBoat'

  # BaseGANBoat hyper-params
  hyper_parameters:
    concurrent: false
    g_interval: 1
    d_interval: 1
    adversarial_weight: 0.1
    lambda_latent: 0.01

  models:
    # Multi-scale VQ-GAN tokenizer
    net:
      path: 'rhcompression.nn.var_vqgan.var_vqgan'
      name: 'VARVQGAN'
      params: 
        base_channels: 64

    # Discriminator (use whichever exists in your zoo; example below keeps DCGAN-style)
    critic:
      path: 'rhadversarial.nn.model_zoo.dcgan_discriminator'
      name: 'DCGANDiscriminator'
      params:
        input_scale: 256          # set to your training image size
        output_scale: 4
        out_channels: 1
        spectral_norm_enabled: true

  losses:
    # --- GAN (hinge) ---
    critic:
      path: 'rhino.nn.losses.gan_losses'
      name: 'HingeGANLoss'
      params: {}
      wrapper:
        mpath: 'rhcore.nn.losses.wrappers.list_of_keys.ListOfKeys'
        params:
          keys: ["real", "fake"]  # BaseGANBoat passes {'real': ..., 'fake': ...}

    # --- reconstruction / feature ---
    pixel_loss:
      path: 'torch.nn'
      name: 'MSELoss'
      params: {}

    latent_loss:
      path: 'torch.nn'
      name: 'MSELoss'
      params: {}

    lpips_loss:
      path: 'lpips'
      name: 'LPIPS'
      params:
        net: 'vgg'

optimization:
  net:
    path: 'torch.optim'
    name: 'Adam'
    params:
      lr: 0.0001
      betas: [0.0, 0.99]
      weight_decay: 0.0
    lr_scheduler: {}

  critic:
    path: 'torch.optim'
    name: 'Adam'
    params:
      lr: 0.0002
      betas: [0.0, 0.99]
      weight_decay: 0.0
    lr_scheduler: {}

  use_ema:
    ema_decay: 0.999
    ema_start: $ema_start

trainer:
  devices: $devices
  max_epochs: $max_epochs
  val_check_epochs: 1
  state_save_epochs: 1
  fup_by_key: # Setup find unused parameters, this is particular useful for DDP. 
    net: True

visualization:
  save_images: true
  first_batch_only: true
  wnb: [0.5, 0.5]
  num_vis_samples: 4

validation:
  target_metric_name: psnr
  metrics:
    psnr:
      path: 'torchmetrics.image'
      name: 'PeakSignalNoiseRatio'
      wrapper: 'rhcore.metrics.wrappers.dict_2_params.Dict2ListParams'
      params:
        data_range: 2.0
    ssim:
      path: 'torchmetrics.image'
      name: 'StructuralSimilarityIndexMeasure'
      wrapper: 'rhcore.metrics.wrappers.dict_2_params.Dict2ListParams'
      params: {}
      
logging:
  root_dir: 'work_dirs'
  name: $experiment_name
  loggers:
    tensorboard:
      path: 'trainer.loggers.tensorboard'
      name: 'TensorBoardLogger'
      params:
        log_dir: 'work_dirs'
        name: $experiment_name

callbacks:
  - path: trainer.callbacks.state_cleaner
    name: KeepTopKStateCallback
    params:
      top_k: 5

_vars:
  devices: [0, 1, 2, 3]
  max_epochs: 200

  train_batch_size: 64
  valid_batch_size: 32
  num_workers: 16

  # point these to your datasets (normalized to [-1,1] in datamodule)
  train_folder_paths:
    gt: data/ffhq/ffhq_imgs/ffhq_256
  valid_folder_paths:
    gt: data/celeba/subsets/celeba_256

  experiment_name: varvqgan_ffhq_256
  ema_start: 1000
